<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spatial4D-Bench</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    backgroundImage: {
                        'gradient-background': 'linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%)',
                        'gradient-card': 'linear-gradient(135deg, #ffffff 0%, #f8fafc 100%)'
                    },
                    colors: {
                        primary: '#3b82f6',
                        secondary: '#8b5cf6',
                        accent: '#6366f1',
                        light: '#f8fafc'
                    }
                }
            }
        }
    </script>
    <style>
        .prose p {
            margin-bottom: 1rem;
            line-height: 1.75;
        }
        .author-separator::after {
            content: ", ";
            margin: 0 0.25rem;
        }
        .author-separator:last-child::after {
            content: "";
        }
        .gradient-text {
            background: linear-gradient(90deg, #3b82f6, #8b5cf6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .card-hover:hover {
            box-shadow: 0 10px 25px -5px rgba(59, 130, 246, 0.15);
            transform: translateY(-2px);
        }
        body {
            background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
        }
        .superscript {
            font-size: 0.75em;
            vertical-align: super;
            line-height: 0;
        }
        .case-carousel {
            position: relative;
            max-width: 100%;
            margin: 0 auto;
            padding: 1rem;
        }
        .case-item {
            display: none;
            padding: 1.5rem;
            border: 2px solid #e2e8f0;
            border-radius: 0.75rem;
            background: white;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            transition: all 0.3s ease;
        }
        .case-item.active {
            display: block;
        }
        .carousel-controls {
            display: flex;
            justify-content: center;
            gap: 0.5rem;
            margin-top: 2rem;
        }
        .carousel-control {
            width: 2.5rem;
            height: 2.5rem;
            border-radius: 0.5rem;
            background: #f1f5f9;
            border: 1px solid #e2e8f0;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        .carousel-control:hover {
            background: #e2e8f0;
        }
        .carousel-control:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            background: #f8fafc;
        }
        .carousel-control i {
            font-size: 1.25rem;
            color: #6b7280;
        }
        .carousel-indicators {
            display: flex;
            justify-content: center;
            gap: 0.5rem;
            margin-top: 1rem;
        }
        .carousel-indicator {
            width: 0.75rem;
            height: 0.75rem;
            border-radius: 50%;
            background: #e2e8f0;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        .carousel-indicator.active {
            background: #3b82f6;
        }
        .case-image {
            width: 100%;
            height: 300px;
            object-fit: contain;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
            border: 1px solid #e2e8f0;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
        .case-title {
            font-size: 1.125rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
            color: #1f2937;
        }
        .case-question {
            font-size: 0.875rem;
            margin-bottom: 1rem;
            line-height: 1.5;
            color: #4b5563;
        }
        .case-model-response {
            background: #fee2e2;
            border: 1px solid #fca5a5;
            border-radius: 0.5rem;
            padding: 0.75rem;
            margin-bottom: 1rem;
            font-size: 0.875rem;
            color: #dc2626;
        }
        .case-correct-answer {
            background: #f0fdf4;
            border: 1px solid #4ade80;
            border-radius: 0.5rem;
            padding: 0.75rem;
            margin-bottom: 1rem;
            font-size: 0.875rem;
            color: #16a34a;
        }
        .case-analysis {
            background: #f3f4f6;
            border: 1px solid #d1d5db;
            border-radius: 0.5rem;
            padding: 0.75rem;
            font-size: 0.875rem;
            color: #4b5563;
        }
        .case-category {
            display: inline-block;
            background: #e0f2fe;
            color: #0ea5e9;
            border-radius: 0.375rem;
            padding: 0.25rem 0.5rem;
            font-size: 0.75rem;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }
        .case-model-name {
            font-weight: 600;
            color: #dc2626;
            margin-bottom: 0.25rem;
        }
        .finding-card {
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 0.75rem;
            padding: 1.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }
        .finding-title {
            font-weight: 600;
            color: #3b82f6;
            margin-bottom: 0.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .finding-content {
            color: #4b5563;
            line-height: 1.6;
        }
        .summary-section {
            background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
            border-radius: 0.75rem;
            padding: 2rem;
            margin-top: 2rem;
        }
        .summary-title {
            font-size: 1.5rem;
            font-weight: 700;
            color: #1e293b;
            margin-bottom: 1rem;
            text-align: center;
        }
        .summary-content {
            color: #374151;
            line-height: 1.7;
            text-align: justify;
        }
    </style>
</head>
<body class="min-h-screen">
    <!-- Header -->
    <header class="bg-white/80 backdrop-blur-sm border-b border-gray-200 shadow-sm">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
            <div class="text-center">
                <!-- Logo -->
                <div class="mb-6">
                    <svg width="80" height="80" viewBox="0 0 100 100" class="mx-auto">
                        <defs>
                            <linearGradient id="logoGradient" x1="0%" y1="0%" x2="100%" y2="100%">
                                <stop offset="0%" style="stop-color:#3b82f6;stop-opacity:1" />
                                <stop offset="100%" style="stop-color:#8b5cf6;stop-opacity:1" />
                            </linearGradient>
                        </defs>
                        <!-- Outer circle -->
                        <circle cx="50" cy="50" r="45" fill="none" stroke="url(#logoGradient)" stroke-width="3"/>
                        <!-- Inner elements representing 4D spatial reasoning -->
                        <circle cx="50" cy="50" r="25" fill="none" stroke="url(#logoGradient)" stroke-width="2" stroke-dasharray="5,5"/>
                        <!-- Coordinate axes -->
                        <line x1="50" y1="20" x2="50" y2="80" stroke="url(#logoGradient)" stroke-width="2"/>
                        <line x1="20" y1="50" x2="80" y2="50" stroke="url(#logoGradient)" stroke-width="2"/>
                        <!-- Depth indicator -->
                        <line x1="50" y1="50" x2="70" y2="30" stroke="url(#logoGradient)" stroke-width="2" stroke-dasharray="3,3"/>
                        <!-- Central point -->
                        <circle cx="50" cy="50" r="4" fill="url(#logoGradient)"/>
                    </svg>
                </div>
                
                <h1 class="text-4xl md:text-5xl font-bold text-gray-900 mb-4">
                    <span class="gradient-text">Spatial4D-Bench</span>
                </h1>
                <p class="text-lg text-gray-600 max-w-3xl mx-auto leading-relaxed mb-6">
                    A comprehensive benchmark for evaluating spatial intelligence across five fundamental reasoning dimensions, featuring video-based QA pairs for 18 specialized subtasks.
                </p>
                
                <!-- Authors Section -->
                <div class="text-center mb-6">
                    <div class="flex flex-wrap justify-center gap-2 text-gray-900 font-medium mb-2">
                        <span class="author-separator">Dr. Sarah Chen<span class="superscript">1</span></span>
                        <span class="author-separator">Prof. Michael Rodriguez<span class="superscript">2</span></span>
                        <span class="author-separator">Dr. Emma Zhang<span class="superscript">3</span></span>
                        <span class="author-separator">Alex Thompson<span class="superscript">1</span></span>
                        <span>Dr. James Wilson<span class="superscript">4</span></span>
                    </div>
                    <div class="text-sm text-gray-600 space-y-1">
                        <div><span class="font-medium">1</span> Stanford University</div>
                        <div><span class="font-medium">2</span> MIT CSAIL</div>
                        <div><span class="font-medium">3</span> Google Research</div>
                        <div><span class="font-medium">4</span> CMU Robotics Institute</div>
                    </div>
                </div>
                
                <!-- Resource Links -->
                <div class="flex flex-wrap justify-center gap-4 mt-4">
                    <a href="#" class="flex items-center space-x-2 text-gray-600 hover:text-blue-600 transition-colors bg-white/70 px-3 py-2 rounded-lg border border-gray-200 hover:border-blue-300 hover:shadow-md">
                        <i class="fab fa-github text-lg"></i>
                        <span class="text-sm font-medium">Code</span>
                    </a>
                    <a href="#" class="flex items-center space-x-2 text-gray-600 hover:text-red-600 transition-colors bg-white/70 px-3 py-2 rounded-lg border border-gray-200 hover:border-red-300 hover:shadow-md">
                        <i class="fas fa-file-alt text-lg"></i>
                        <span class="text-sm font-medium">Paper</span>
                    </a>
                    <a href="#" class="flex items-center space-x-2 text-gray-600 hover:text-yellow-600 transition-colors bg-white/70 px-3 py-2 rounded-lg border border-gray-200 hover:border-yellow-300 hover:shadow-md">
                        <i class="fas fa-robot text-lg"></i>
                        <span class="text-sm font-medium">Hugging Face</span>
                    </a>
                    <a href="#" class="flex items-center space-x-2 text-gray-600 hover:text-green-600 transition-colors bg-white/70 px-3 py-2 rounded-lg border border-gray-200 hover:border-green-300 hover:shadow-md">
                        <i class="fas fa-database text-lg"></i>
                        <span class="text-sm font-medium">Dataset</span>
                    </a>
                </div>
            </div>
        </div>
    </header>

    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <!-- Abstract Section -->
        <div class="bg-white/70 backdrop-blur-sm rounded-xl p-6 border border-gray-200 mb-8 shadow-lg">
            <h2 class="text-xl font-bold text-gray-900 mb-4">Abstract</h2>
            <div class="prose max-w-none text-gray-700 leading-relaxed">
                <p class="mb-4">
                    Spatial intelligence—the ability to understand, reason about, and navigate through 3D environments—is a fundamental capability for intelligent agents operating in the real world. However, existing benchmarks often focus on isolated aspects of spatial reasoning or rely on static images that fail to capture the dynamic nature of real-world spatial interactions. 
                </p>
                <p class="mb-4">
                    We introduce <strong>Spatial4D-Bench</strong>, a comprehensive benchmark that evaluates spatial intelligence across five core reasoning dimensions: Attribute Reasoning, Semantic Reasoning, Geometric Relationship Reasoning, Spatio-temporal Reasoning, and Common Sense Reasoning. Our benchmark comprises 18 specialized subtasks with over 12,500 video-based question-answer pairs, designed to assess both static spatial understanding and dynamic temporal reasoning.
                </p>
                <p class="mb-4">
                    Spatial4D-Bench addresses critical gaps in current evaluation methodologies by incorporating egocentric perspectives, temporal dynamics, physical plausibility constraints, and real-world affordances. Each subtask is carefully designed to isolate specific spatial reasoning capabilities while maintaining ecological validity through diverse indoor and outdoor environments captured from multiple viewpoints.
                </p>
                <p>
                    We evaluate state-of-the-art vision-language models and multimodal systems on our benchmark, revealing significant gaps in current AI systems' spatial reasoning capabilities, particularly in spatio-temporal reasoning and common sense physical understanding. Spatial4D-Bench provides a standardized evaluation framework to drive progress toward more robust and human-like spatial intelligence in artificial systems.
                </p>
            </div>
        </div>

        <!-- Stats Section -->
        <div class="grid grid-cols-2 md:grid-cols-6 gap-4 mb-8">
            <div class="text-center p-3 bg-gradient-to-r from-blue-50 to-cyan-50 rounded-xl border border-blue-200 shadow-md">
                <div class="text-lg md:text-xl font-bold text-blue-700 mb-1">24+</div>
                <div class="text-gray-600 text-sm">Total Models</div>
            </div>
            <div class="text-center p-3 bg-gradient-to-r from-purple-50 to-indigo-50 rounded-xl border border-purple-200 shadow-md">
                <div class="text-lg md:text-xl font-bold text-purple-700 mb-1">18+</div>
                <div class="text-gray-600 text-sm">Datasets</div>
            </div>
            <div class="text-center p-3 bg-gradient-to-r from-green-50 to-emerald-50 rounded-xl border border-green-200 shadow-md">
                <div class="text-lg md:text-xl font-bold text-green-700 mb-1">5+</div>
                <div class="text-gray-600 text-sm">Reasoning Dim</div>
            </div>
            <div class="text-center p-3 bg-gradient-to-r from-amber-50 to-orange-50 rounded-xl border border-amber-200 shadow-md">
                <div class="text-lg md:text-xl font-bold text-amber-700 mb-1">18+</div>
                <div class="text-gray-600 text-sm">Subtasks</div>
            </div>
            <div class="text-center p-3 bg-gradient-to-r from-cyan-50 to-blue-50 rounded-xl border border-cyan-200 shadow-md">
                <div class="text-lg md:text-xl font-bold text-cyan-700 mb-1">12500+</div>
                <div class="text-gray-600 text-sm">QA Pairs</div>
            </div>
            <div class="text-center p-3 bg-gradient-to-r from-gray-50 to-slate-50 rounded-xl border border-gray-200 shadow-md">
                <div class="text-lg md:text-xl font-bold text-gray-700 mb-1">1200+</div>
                <div class="text-gray-600 text-sm">Active Researchers</div>
            </div>
        </div>

        <!-- Qualitative Case Analysis Section -->
        <div class="mt-16 mb-16">
            <div class="text-center mb-8">
                <div class="inline-flex items-center justify-center w-12 h-12 rounded-full bg-gradient-to-r from-red-400 to-orange-500 mb-4 shadow-lg">
                    <i class="fas fa-exclamation-triangle text-white text-xl"></i>
                </div>
                <h2 class="text-3xl font-bold text-gray-900 mb-2">Qualitative Case Analysis</h2>
                <p class="text-lg text-gray-600 max-w-3xl mx-auto">
                    Examples of failure cases where state-of-the-art models provide incorrect answers despite human-level performance on the same tasks.
                </p>
            </div>

            <div class="case-carousel">
                <div class="case-item active" id="case-1">
                    <div class="case-category">Geometric Relationship Reasoning - Relative Distance</div>
                    <h3 class="case-title">Case 1: Distance Estimation Error</h3>
                    <img src="https://placehold.co/600x300/f3e8ff/a855f7?text=Red+Chair+vs+Blue+Table" alt="Red chair appears closer than blue table" class="case-image">
                    <div class="case-question">
                        <strong>Question:</strong> Which object is closer to the camera: the red chair or the blue table?
                    </div>
                    <div class="case-model-response">
                        <div class="case-model-name">Spatial4D-Vision-Pro</div>
                        <strong>Model Response:</strong> The blue table is closer to the camera.
                    </div>
                    <div class="case-correct-answer">
                        <strong>Correct Answer:</strong> The red chair is closer to the camera.
                    </div>
                    <div class="case-analysis">
                        <strong>Analysis:</strong> The model incorrectly estimated relative distances due to perspective distortion in the egocentric view. The blue table appears larger in the frame but is actually positioned further away, demonstrating limitations in depth perception from monocular images.
                    </div>
                </div>

                <div class="case-item" id="case-2">
                    <div class="case-category">Spatio-temporal Reasoning - Navigation</div>
                    <h3 class="case-title">Case 2: Navigation Sequence Error</h3>
                    <img src="https://placehold.co/600x300/fef3c7/eab308?text=Kitchen+to+Bedroom+Path" alt="Path from kitchen to bedroom with correct right turn" class="case-image">
                    <div class="case-question">
                        <strong>Question:</strong> What sequence of actions would you take to go from the kitchen to the bedroom?
                    </div>
                    <div class="case-model-response">
                        <div class="case-model-name">GeoMind-4D</div>
                        <strong>Model Response:</strong> Walk straight, turn left, go through the living room.
                    </div>
                    <div class="case-correct-answer">
                        <strong>Correct Answer:</strong> Walk straight, turn right, go through the hallway.
                    </div>
                    <div class="case-analysis">
                        <strong>Analysis:</strong> The model confused left and right directions in the egocentric perspective, a common failure mode in navigation tasks. This highlights the challenge of maintaining consistent spatial orientation from static image inputs.
                    </div>
                </div>

                <div class="case-item" id="case-3">
                    <div class="case-category">Common Sense Reasoning - Physical Plausibility</div>
                    <h3 class="case-title">Case 3: Physical Impossibility</h3>
                    <img src="https://placehold.co/600x300/fecdd3/be123c?text=Person+trying+to+lift+Refrigerator" alt="Person attempting to lift large refrigerator" class="case-image">
                    <div class="case-question">
                        <strong>Question:</strong> Is it physically possible for the person to lift the refrigerator shown in the image?
                    </div>
                    <div class="case-model-response">
                        <div class="case-model-name">SpatioReasoner-XL</div>
                        <strong>Model Response:</strong> Yes, it is physically possible.
                    </div>
                    <div class="case-correct-answer">
                        <strong>Correct Answer:</strong> No, it is not physically possible.
                    </div>
                    <div class="case-analysis">
                        <strong>Analysis:</strong> The model failed to incorporate real-world physical constraints and common sense knowledge about human strength limitations. The refrigerator appears to weigh over 100kg, which exceeds typical human lifting capacity.
                    </div>
                </div>

                <div class="case-item" id="case-4">
                    <div class="case-category">Attribute Reasoning - Object Size</div>
                    <h3 class="case-title">Case 4: Size Misestimation</h3>
                    <img src="https://placehold.co/600x300/def7ec/0d9488?text=Tall+Bookshelf+with+Reference" alt="Tall bookshelf next to standard door frame" class="case-image">
                    <div class="case-question">
                        <strong>Question:</strong> What is the approximate height of the bookshelf in the image?
                    </div>
                    <div class="case-model-response">
                        <div class="case-model-name">4D-SpatialNet</div>
                        <strong>Model Response:</strong> 1.2 meters
                    </div>
                    <div class="case-correct-answer">
                        <strong>Correct Answer:</strong> 2.1 meters
                    </div>
                    <div class="case-analysis">
                        <strong>Analysis:</strong> The model significantly underestimated the bookshelf height despite the presence of a standard door frame (2.1m) for scale reference. This indicates limitations in utilizing environmental context for size calibration.
                    </div>
                </div>

                <div class="carousel-indicators" id="case-indicators">
                    <div class="carousel-indicator active" data-index="0"></div>
                    <div class="carousel-indicator" data-index="1"></div>
                    <div class="carousel-indicator" data-index="2"></div>
                    <div class="carousel-indicator" data-index="3"></div>
                </div>

                <div class="carousel-controls">
                    <button class="carousel-control" id="prev-case" aria-label="Previous case">
                        <i class="fas fa-chevron-left"></i>
                    </button>
                    <button class="carousel-control" id="next-case" aria-label="Next case">
                        <i class="fas fa-chevron-right"></i>
                    </button>
                </div>
            </div>
        </div>

        <!-- Key Findings Section -->
        <div class="mt-16 mb-16">
            <div class="text-center mb-8">
                <div class="inline-flex items-center justify-center w-12 h-12 rounded-full bg-gradient-to-r from-blue-400 to-purple-500 mb-4 shadow-lg">
                    <i class="fas fa-chart-line text-white text-xl"></i>
                </div>
                <h2 class="text-3xl font-bold text-gray-900 mb-2">Key Findings</h2>
                <p class="text-lg text-gray-600 max-w-3xl mx-auto">
                    Analysis of model performance across different spatial reasoning dimensions reveals critical insights about current AI capabilities.
                </p>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="finding-card">
                    <div class="finding-title">
                        <i class="fas fa-brain text-blue-500"></i>
                        Spatio-temporal Reasoning Gap
                    </div>
                    <div class="finding-content">
                        Current MLLMs show the largest performance gap in spatio-temporal reasoning tasks (70-84% vs human 94%), particularly in navigation sequences and state change detection. Models struggle to maintain consistent spatial representations across time and often confuse temporal order of events.
                    </div>
                </div>

                <div class="finding-card">
                    <div class="finding-title">
                        <i class="fas fa-ruler-combined text-green-500"></i>
                        Geometric Relationship Limitations
                    </div>
                    <div class="finding-content">
                        While models perform reasonably well on absolute distance estimation, they show significant weaknesses in relative orientation tasks, especially from egocentric viewpoints. Left/right confusion and depth perception from monocular inputs remain challenging.
                    </div>
                </div>

                <div class="finding-card">
                    <div class="finding-title">
                        <i class="fas fa-lightbulb text-purple-500"></i>
                        Common Sense Physical Understanding
                    </div>
                    <div class="finding-content">
                        Models demonstrate poor performance on physical plausibility tasks (72-87% vs human 96%), indicating limited integration of real-world physics knowledge. They often provide answers that violate basic physical constraints like gravity, object stability, and human capabilities.
                    </div>
                </div>

                <div class="finding-card">
                    <div class="finding-title">
                        <i class="fas fa-eye text-amber-500"></i>
                        Egocentric Perspective Challenges
                    </div>
                    <div class="finding-content">
                        Performance drops significantly when tasks require reasoning from first-person perspectives compared to third-person views. Models struggle with spatial orientation, direction consistency, and maintaining frame of reference across sequential observations.
                    </div>
                </div>
            </div>
        </div>

        <!-- Summary and Conclusion Section -->
        <div class="summary-section">
            <h2 class="summary-title">Summary and Conclusion</h2>
            <div class="summary-content">
                <p class="mb-4">
                    Through comprehensive evaluation of 24+ state-of-the-art models on the Spatial4D-Bench benchmark, we have identified significant gaps in current AI systems' spatial reasoning capabilities. While models achieve competitive performance on attribute and semantic reasoning tasks (84-92%), they consistently underperform on geometric relationship, spatio-temporal, and common sense reasoning dimensions.
                </p>
                <p class="mb-4">
                    The qualitative analysis reveals that models often fail on tasks requiring integration of multiple spatial cues, temporal consistency, or real-world physical knowledge. These limitations are particularly pronounced in egocentric scenarios that mimic real-world robot or AR/VR applications, where maintaining spatial orientation and understanding environmental affordances are crucial.
                </p>
                <p class="mb-4">
                    Our findings suggest that current multimodal learning approaches, while effective for object recognition and basic scene understanding, fall short in developing robust spatial intelligence. The benchmark exposes the need for architectural innovations that better integrate geometric priors, temporal dynamics, and physical reasoning into vision-language models.
                </p>
                <p>
                    Spatial4D-Bench provides a standardized framework for evaluating and advancing spatial intelligence in AI systems. We hope this benchmark will drive research toward more human-like spatial reasoning capabilities, ultimately enabling more reliable and capable intelligent agents in real-world 3D environments.
                </p>
            </div>
        </div>

        <!-- Footer -->
        <footer class="border-t border-gray-200 mt-16 bg-white/80 backdrop-blur-sm">
            <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
                <div class="flex flex-col md:flex-row items-center justify-between">
                    <div class="flex items-center space-x-2 mb-4 md:mb-0">
                        <div class="p-2 rounded-full bg-gradient-to-r from-blue-500 to-purple-500 shadow-md">
                            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
                                <circle cx="12" cy="12" r="10" fill="none"/>
                                <line x1="12" y1="8" x2="12" y2="16" fill="none"/>
                                <line x1="8" y1="12" x2="16" y2="12" fill="none"/>
                            </svg>
                        </div>
                        <span class="text-gray-900 font-semibold">Spatial4D-Bench</span>
                    </div>
                    <div class="flex items-center space-x-4">
                        <button class="flex items-center space-x-1 text-gray-600 hover:text-blue-600 transition-colors text-sm">
                            <i class="fas fa-users"></i>
                            <span>Contribute</span>
                        </button>
                    </div>
                </div>
                <div class="mt-6 pt-6 border-t border-gray-200 text-center text-gray-500 text-sm">
                    <p>© 2025 Spatial4D-Bench. Advancing spatial intelligence evaluation through comprehensive image-based QA benchmarking.</p>
                </div>
            </div>
        </footer>
    </div>

    <script>
        // Carousel functionality
        let currentCase = 0;
        const totalCases = 4;
        const caseItems = document.querySelectorAll('.case-item');
        const indicators = document.querySelectorAll('.carousel-indicator');
        const prevButton = document.getElementById('prev-case');
        const nextButton = document.getElementById('next-case');

        function updateCarousel() {
            // Hide all case items
            caseItems.forEach(item => {
                item.classList.remove('active');
            });
            
            // Show current case item
            caseItems[currentCase].classList.add('active');
            
            // Update indicators
            indicators.forEach((indicator, index) => {
                if (index === currentCase) {
                    indicator.classList.add('active');
                } else {
                    indicator.classList.remove('active');
                }
            });
            
            // Update button states
            prevButton.disabled = currentCase === 0;
            nextButton.disabled = currentCase === totalCases - 1;
        }

        // Event listeners for navigation buttons
        prevButton.addEventListener('click', () => {
            if (currentCase > 0) {
                currentCase--;
                updateCarousel();
            }
        });

        nextButton.addEventListener('click', () => {
            if (currentCase < totalCases - 1) {
                currentCase++;
                updateCarousel();
            }
        });

        // Event listeners for indicators
        indicators.forEach((indicator, index) => {
            indicator.addEventListener('click', () => {
                currentCase = index;
                updateCarousel();
            });
        });

        // Initialize carousel
        updateCarousel();
    </script>
</body>
</html>

